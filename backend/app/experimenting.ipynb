{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23324a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database path: /home/asj53/BOScheduling/myproject/app/data/schedules.db\n",
      "Database URL: sqlite:////home/asj53/BOScheduling/myproject/app/data/schedules.db\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from functools import lru_cache\n",
    "from sqlalchemy import create_engine, text\n",
    "from typing import List\n",
    "\n",
    "# ── CONFIGURE ────────────────────────────────────────────────────────────────\n",
    "# Database configuration - adjust paths as needed\n",
    "def get_db_path():\n",
    "    \"\"\"Get database path, handling both script and notebook contexts.\"\"\"\n",
    "    try:\n",
    "        # When running as a script\n",
    "        script_dir = os.path.dirname(__file__)\n",
    "        return os.path.join(script_dir, '..', 'data', 'schedules.db')\n",
    "    except NameError:\n",
    "        # When running in notebook or interactive environment\n",
    "        # Update this path to match your actual database location\n",
    "        return os.path.abspath('data/schedules.db')  # Adjust this path as needed\n",
    "\n",
    "DB_PATH = get_db_path()\n",
    "DB_URL = f\"sqlite:///{DB_PATH}\"\n",
    "SEMESTER = \"sp25\"  # Update as needed\n",
    "\n",
    "print(f\"Database path: {DB_PATH}\")\n",
    "print(f\"Database URL: {DB_URL}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c414884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_name:  thomp:\n",
      "ASSIGNMENT_TYPE:  block\n",
      "semester ,  sp25\n",
      "co     Unnamed: 0  72-0103  1-9185  MLG17  1-8222  1-6240  1-5549  1-8021  \\\n",
      "0      72-0103        0       1     52       0       1       1       0   \n",
      "1       1-9185        1       0      0       0       0       0       0   \n",
      "2        MLG17       52       0      0       0      15       0       0   \n",
      "3       1-8222        0       0      0       0       1       0       0   \n",
      "4       1-6240        1       0     15       1       0       2       0   \n",
      "..         ...      ...     ...    ...     ...     ...     ...     ...   \n",
      "561     1-9455        0       0      0       0       0       0       0   \n",
      "562     1-0003        0       0      0       0       0       0       0   \n",
      "563    1-21192        0       0      0       0       0       0       0   \n",
      "564     1-9034        0       0      0       0       0       0       0   \n",
      "565    1-19927        0       0      0       0       0       0       0   \n",
      "\n",
      "     1-8767  1-8181  ...  1-10951  1-9806  1-0055  1-5914  1-0027  1-9455  \\\n",
      "0        33       1  ...        0       1       0       0       0       0   \n",
      "1         0       0  ...        0       0       0       0       0       0   \n",
      "2        37       4  ...        0       0       3       0       0       0   \n",
      "3         0       0  ...        0       0       0       0       0       0   \n",
      "4         1       2  ...        0       0       0       1       0       0   \n",
      "..      ...     ...  ...      ...     ...     ...     ...     ...     ...   \n",
      "561       0       0  ...        0       0       0       0       0       0   \n",
      "562       0       0  ...        0       0       0       0       0       0   \n",
      "563       0       0  ...        0       0       0       0       0       0   \n",
      "564       0       0  ...        0       0       0       0       0       0   \n",
      "565       0       0  ...        0       0       0       0       0       0   \n",
      "\n",
      "     1-0003  1-21192  1-9034  1-19927  \n",
      "0         0        0       0        0  \n",
      "1         0        0       0        0  \n",
      "2         0        0       0        0  \n",
      "3         0        0       0        0  \n",
      "4         0        0       0        0  \n",
      "..      ...      ...     ...      ...  \n",
      "561       0        0       0        0  \n",
      "562       0        0       0        0  \n",
      "563       0        0       0        0  \n",
      "564       0        0       0        0  \n",
      "565       0        0       0        0  \n",
      "\n",
      "[566 rows x 567 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "from config.settings import SAVE_PATH, DATA_PATH, UI_PATH , SEMESTER\n",
    "from globals.build_global_sets import normalize_and_merge\n",
    "times = ['']\n",
    "def slots_to_time(slots):\n",
    "    d = {}\n",
    "    if 'fa' in SEMESTER : \n",
    "        d=  {\n",
    "            1: 'Dec 13, 9am', \n",
    "            2: 'Dec 13, 2pm',\n",
    "            3: 'Dec 13, 7pm',\n",
    "            4: 'Dec 14, 9am',\n",
    "            5: 'Dec 14, 2pm',\n",
    "            6: 'Dec 14, 7pm',\n",
    "            7: 'Dec 15, 9am',\n",
    "            8: 'Dec 15, 2pm',\n",
    "            9: 'Dec 15, 7pm',\n",
    "            10: 'Dec 16, 9am',\n",
    "            11: 'Dec 16, 2pm',\n",
    "            12: 'Dec 16, 7pm',\n",
    "            13: 'Dec 17, 9am',\n",
    "            14: 'Dec 17, 2pm',\n",
    "            15: 'Dec 17, 7pm',\n",
    "            16: 'Dec 18, 9am',\n",
    "            17: 'Dec 18, 2pm',\n",
    "            18: 'Dec 18, 7pm',\n",
    "            19: 'Dec 19, 9am',\n",
    "            20: 'Dec 19, 2pm',\n",
    "            21: 'Dec 19, 7pm',\n",
    "            22: 'Dec 20, 9am',\n",
    "            23: 'Dec 20, 2pm',\n",
    "            24: 'Dec 20, 7pm',\n",
    "            25: 'Dec 21, 9am',\n",
    "            26: 'Dec 21, 2pm',\n",
    "            27: 'Dec 21, 7pm'}\n",
    "    else:  \n",
    "        d=   {\n",
    "        1:  'May 11, 9am',\n",
    "        2:  'May 11, 2pm',\n",
    "        3:  'May 11, 7pm',\n",
    "        4:  'May 12, 9am',\n",
    "        5:  'May 12, 2pm',\n",
    "        6:  'May 12, 7pm',\n",
    "        7:  'May 13, 9am',\n",
    "        8:  'May 13, 2pm',\n",
    "        9:  'May 13, 7pm',\n",
    "        10: 'May 14, 9am',\n",
    "        11: 'May 14, 2pm',\n",
    "        12: 'May 14, 7mm',\n",
    "        13: 'May 15, 9am',\n",
    "        14: 'May 15, 2pm',\n",
    "        15: 'May 15, 7pm',\n",
    "        16: 'May 16, 9am',\n",
    "        17: 'May 16, 2pm',\n",
    "        18: 'May 16, 7pm',\n",
    "        19: 'May 17, 9am',\n",
    "        20: 'May 17, 2pm',\n",
    "        21: 'May 17, 7pm',\n",
    "        22: 'May 18, 9am',\n",
    "        23: 'May 18, 2pm',\n",
    "        24: 'May 18, 7pm', \n",
    "        25: 'May 19, 9am', \n",
    "        26: 'May 19, 2pm',\n",
    "        27: 'May 19, 7pm' }\n",
    "    \n",
    "    return [d[s] for s in slots]\n",
    "# Create the chart\n",
    "def get_plot(schedule_name, name):\n",
    "  sched = pd.read_csv(SAVE_PATH +'/schedules/' + schedule_name )\n",
    "  exam_sizes = pd.read_csv(DATA_PATH + '/exam_sizes.csv')\n",
    "  slots = np.unique(sched['slot'].values)\n",
    "\n",
    "  num_slots1 = len(slots)\n",
    "  num_slots2 = int(max(slots))\n",
    "  h = np.zeros(num_slots2)\n",
    "  h1 = np.zeros(num_slots2)\n",
    "  h2 = np.zeros(num_slots2)\n",
    "  h3 = np.zeros(num_slots2)\n",
    "  h4 = np.zeros(num_slots2)\n",
    "  for s in slots:\n",
    "      s = int(s)\n",
    "      exams = sched[sched['slot']==s]['exam'].tolist()\n",
    "      exams_over_400 = sched[(sched['slot']==s) & (sched['size']>= 400)]['exam'].tolist()\n",
    "      exams_in_300_400 = sched[(sched['slot']==s) & (sched['size']>= 300) & (sched['size']< 400)]['exam'].tolist()\n",
    "      exams_in_200_300 = sched[(sched['slot']==s) & (sched['size']>= 200) & (sched['size']< 300)]['exam'].tolist()\n",
    "      exams_in_100_200 = sched[(sched['slot']==s) & (sched['size']>= 100) & (sched['size']< 200)]['exam'].tolist()\n",
    "      sizes_over_400 = exam_sizes[exam_sizes['exam'].isin(exams_over_400)]['size'].sum()\n",
    "      sizes_in_300_400 = exam_sizes[exam_sizes['exam'].isin(exams_in_300_400)]['size'].sum()\n",
    "      sizes_in_200_300 = exam_sizes[exam_sizes['exam'].isin(exams_in_200_300 )]['size'].sum()\n",
    "      sizes_in_100_200 = exam_sizes[exam_sizes['exam'].isin(exams_in_100_200 )]['size'].sum()\n",
    "      sizes = exam_sizes[exam_sizes['exam'].isin(exams)]['size'].sum()\n",
    "      h[s-1] = sizes\n",
    "      h1[s-1] = sizes_over_400\n",
    "      h2[s-1] = sizes_in_300_400\n",
    "      h3[s-1] = sizes_in_200_300\n",
    "      h4[s-1] = sizes_in_100_200\n",
    "\n",
    "  plt.style.use('classic')\n",
    "  plt.figure(figsize=(18, 12))\n",
    "\n",
    "  # plt.bar(x=slots, height=[max(h)]*num_slots1, color='red', alpha=0.4, width = 1, align = 'center')       \n",
    "  plt.bar(x=range(1,num_slots2+1), height=h1, align='center', width=1, \n",
    "          color = 'tab:red', label = \"Exams w/ over 400 students\")\n",
    "  plt.bar(x=range(1,num_slots2+1), height=h2, align='center', width=1, \n",
    "          bottom = h1, color = 'tab:orange', label = \"Exams w/ over 300 but less than 400 students\")\n",
    "  plt.bar(x=range(1,num_slots2+1), height=h3, align='center', width=1, \n",
    "          bottom = h1+h2, color = 'gold', label = \"Exams w/ over 200 but less than 300 students\")\n",
    "  plt.bar(x=range(1,num_slots2+1), height=h4, align='center', width=1, \n",
    "          bottom = h1+h2+h3, color = 'pink', label = \"Exams w/ over 100 but less than 200 students\")\n",
    "\n",
    "  plt.bar(x=range(1,num_slots2+1), height=h-h1-h2-h3-h4, align='center',\n",
    "          bottom = h1+h2+h3+h4, width=1, color = 'tab:purple', label = \"Other Exams\")\n",
    "\n",
    "  plt.xlabel('Times', fontsize=20)\n",
    "  plt.xticks(np.arange(1, num_slots2 + 1), slots_to_time(np.arange(1, num_slots2 + 1)), rotation = 90, fontsize=16)\n",
    "  plt.yticks(fontsize = 16)\n",
    "  plt.ylabel('Number of students',  fontsize=20)\n",
    "  plt.title('Number of students taking an exam in each time slot',  fontsize=25)\n",
    "  plt.legend(loc = 'best', fontsize=14)\n",
    "  plt.savefig(UI_PATH + name + '.png')\n",
    "  \n",
    "  plt.show()\n",
    "\n",
    "def last_day(sched_name, save_name):\n",
    "    #goop['Exam Block'] = \n",
    "    #sched, by_student_block = normalize_and_merge(goop,)\n",
    "    sched = pd.read_csv(SAVE_PATH + '/schedules/' + sched_name)\n",
    "    print(sched)\n",
    "    enrl_df = pd.read_csv(DATA_PATH + '/enrl.csv')\n",
    "    enrl_df = enrl_df.merge(sched, left_on = 'Exam Key', right_on = 'Exam Group')\n",
    "    by_student_block = enrl_df.groupby('anon-netid')['slot'].apply(list).reset_index(name='slots') #create_by_student_slot_df(exam_df, schedule_dict)\n",
    "    by_student_block['last_block'] = by_student_block['slots'].apply(lambda x: max(x)).copy()\n",
    "    last_block_counts = by_student_block['last_block'].value_counts().reset_index()\n",
    "    last_block_counts.columns = ['last_block', 'occurrences']\n",
    "\n",
    "    last_block_counts = last_block_counts.sort_values(by='last_block').reset_index(drop=True)\n",
    "    print('last_block_counts' , last_block_counts )\n",
    "\n",
    "    slots = np.unique(sched['slot'].values)\n",
    "    # Ensure num_slots2 is an integer for range function\n",
    "    num_slots2 = int(max(slots)) if len(slots) > 0 else 0\n",
    "\n",
    "    print('slot , ' , slots)\n",
    "    h = np.zeros(num_slots2)\n",
    "\n",
    "    # Convert last_block_counts to a dictionary for efficient lookup\n",
    "    counts_dict = last_block_counts.set_index('last_block')['occurrences'].to_dict()\n",
    "\n",
    "    for s in range(1, num_slots2 + 1): # Iterate through all possible slot numbers\n",
    "        # Get the occurrence count from the dictionary, defaulting to 0 if not found\n",
    "        h[s-1] = counts_dict.get(float(s), 0)\n",
    "\n",
    "    plt.style.use('classic')\n",
    "    plt.figure(figsize=(18, 12))\n",
    "    plt.bar(x=range(1,num_slots2+1), height=h, align='center', width=1, color = 'pink')\n",
    "\n",
    "    plt.xlabel('Times', fontsize=20)\n",
    "    # Ensure the ticks cover all possible slots up to num_slots2\n",
    "    plt.xticks(np.arange(1, num_slots2 + 1), slots_to_time(np.arange(1, num_slots2 + 1)), rotation = 90, fontsize=16)\n",
    "    plt.yticks(fontsize = 16)\n",
    "    plt.ylabel('Number of students',  fontsize=20)\n",
    "    plt.title('Number of students taking their last exam in each time slot',  fontsize=25)\n",
    "    plt.savefig(UI_PATH +save_name+ '_dist.png' )\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5594b12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "engine = create_engine(DB_URL, echo=False)  # Set echo=True for debugging\n",
    "\n",
    "def get_schedule_files(date_prefix: str, semester: str = SEMESTER) -> List[str]:\n",
    "    \"\"\"Get schedule IDs from database that match the given date prefix.\"\"\"\n",
    "    print('Getting schedules for prefix:', date_prefix)\n",
    "    \n",
    "    with engine.begin() as conn:\n",
    "        result = conn.execute(text(\"\"\"\n",
    "            SELECT DISTINCT s.schedule_id \n",
    "            FROM schedule_plots s\n",
    "            JOIN metrics m ON s.schedule_id = m.schedule_id\n",
    "            WHERE s.schedule_id LIKE :prefix \n",
    "            AND m.semester = :semester\n",
    "            ORDER BY s.schedule_id\n",
    "        \"\"\"), {\n",
    "            \"prefix\": f\"{date_prefix}%\",\n",
    "            \"semester\": semester\n",
    "        })\n",
    "        \n",
    "        schedule_ids = [row.schedule_id for row in result]\n",
    "        print(f\"Found {len(schedule_ids)} schedules matching prefix '{date_prefix}'\")\n",
    "        return schedule_ids\n",
    "\n",
    "def check_plot_exists(schedule_id: str, plot_type: str = 'sched_plot') -> bool:\n",
    "    \"\"\"Check if a plot exists in the database for the given schedule_id.\"\"\"\n",
    "    with engine.begin() as conn:\n",
    "        result = conn.execute(text(\"\"\"\n",
    "            SELECT 1 FROM schedule_plots \n",
    "            WHERE schedule_id = :schedule_id \n",
    "            AND :plot_type IS NOT NULL\n",
    "        \"\"\"), {\n",
    "            \"schedule_id\": schedule_id,\n",
    "            \"plot_type\": plot_type\n",
    "        })\n",
    "        return result.fetchone() is not None\n",
    "\n",
    "def update_plot_in_db(schedule_id: str, plot_type: str, plot_filename: str, semester: str = SEMESTER):\n",
    "    \"\"\"Update the plot information in the database.\"\"\"\n",
    "    with engine.begin() as conn:\n",
    "        # Check if record exists\n",
    "        existing = conn.execute(text(\"\"\"\n",
    "            SELECT schedule_id FROM schedule_plots \n",
    "            WHERE schedule_id = :schedule_id\n",
    "        \"\"\"), {\"schedule_id\": schedule_id}).fetchone()\n",
    "        \n",
    "        if existing:\n",
    "            # Update existing record\n",
    "            if plot_type == 'sched_plot':\n",
    "                conn.execute(text(\"\"\"\n",
    "                    UPDATE schedule_plots \n",
    "                    SET sched_plot = :plot_filename\n",
    "                    WHERE schedule_id = :schedule_id\n",
    "                \"\"\"), {\n",
    "                    \"plot_filename\": plot_filename,\n",
    "                    \"schedule_id\": schedule_id\n",
    "                })\n",
    "            elif plot_type == 'last_plot':\n",
    "                conn.execute(text(\"\"\"\n",
    "                    UPDATE schedule_plots \n",
    "                    SET last_plot = 1\n",
    "                    WHERE schedule_id = :schedule_id\n",
    "                \"\"\"), {\"schedule_id\": schedule_id})\n",
    "        else:\n",
    "            # Insert new record\n",
    "            sched_plot = plot_filename if plot_type == 'sched_plot' else None\n",
    "            last_plot = 1 if plot_type == 'last_plot' else 0\n",
    "            \n",
    "            conn.execute(text(\"\"\"\n",
    "                INSERT INTO schedule_plots (schedule_id, sched_plot, last_plot, semester)\n",
    "                VALUES (:schedule_id, :sched_plot, :last_plot, :semester)\n",
    "            \"\"\"), {\n",
    "                \"schedule_id\": schedule_id,\n",
    "                \"sched_plot\": sched_plot,\n",
    "                \"last_plot\": last_plot,\n",
    "                \"semester\": semester\n",
    "            })\n",
    "\n",
    "def plot_exists_on_disk(schedule_id: str, plot_suffix: str = '', plots_dir: str = None) -> bool:\n",
    "    \"\"\"Check if plot file exists on disk.\"\"\"\n",
    "    if plots_dir is None:\n",
    "        try:\n",
    "            # When running as a script\n",
    "            plots_dir = os.path.join(os.path.dirname(__file__), 'static', 'plots')\n",
    "        except NameError:\n",
    "            # When running in notebook - adjust this path as needed\n",
    "            plots_dir = os.path.abspath('static/plots')  # Update this path\n",
    "    \n",
    "    plot_filename = f\"{schedule_id}{plot_suffix}.png\"\n",
    "    plot_path = os.path.join(plots_dir, plot_filename)\n",
    "    return os.path.exists(plot_path)\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def generate_plots_for_files(date_prefix: str, semester: str = SEMESTER):\n",
    "    \"\"\"Generate missing schedule and distribution plots for all files matching prefix.\"\"\"\n",
    "    schedule_ids = get_schedule_files(date_prefix, semester)\n",
    "    print(\"PLOT SCHEDULE IDs:\", schedule_ids)\n",
    "    \n",
    "    for schedule_id in schedule_ids:\n",
    "        # Check and generate regular schedule plot\n",
    "        if not plot_exists_on_disk(schedule_id):\n",
    "            print(f\"Generating schedule plot for {schedule_id}\")\n",
    "            get_plot(schedule_id, schedule_id)  # Assuming get_plot function exists\n",
    "            # Update database after successful plot generation\n",
    "            plot_filename = f\"{schedule_id}.png\"\n",
    "            update_plot_in_db(schedule_id, 'sched_plot', plot_filename, semester)\n",
    "        \n",
    "        # Check and generate distribution plot\n",
    "        if not plot_exists_on_disk(schedule_id, '_dist'):\n",
    "            print(f\"Generating distribution plot for {schedule_id}\")\n",
    "            last_day(schedule_id, schedule_id)  # Assuming last_day function exists\n",
    "            # Update database after successful plot generation\n",
    "            update_plot_in_db(schedule_id, 'last_plot', f\"{schedule_id}_dist.png\", semester)\n",
    "\n",
    "def get_schedule_plot_info(schedule_id: str) -> dict:\n",
    "    \"\"\"Get plot information for a specific schedule from the database.\"\"\"\n",
    "    with engine.begin() as conn:\n",
    "        result = conn.execute(text(\"\"\"\n",
    "            SELECT schedule_id, sched_plot, last_plot, semester\n",
    "            FROM schedule_plots\n",
    "            WHERE schedule_id = :schedule_id\n",
    "        \"\"\"), {\"schedule_id\": schedule_id})\n",
    "        \n",
    "        row = result.fetchone()\n",
    "        if row:\n",
    "            return {\n",
    "                'schedule_id': row.schedule_id,\n",
    "                'sched_plot': row.sched_plot,\n",
    "                'has_last_plot': bool(row.last_plot),\n",
    "                'semester': row.semester\n",
    "            }\n",
    "        return None\n",
    "\n",
    "def get_all_plots_for_prefix(date_prefix: str, semester: str = SEMESTER) -> List[dict]:\n",
    "    \"\"\"Get all plot information for schedules matching the prefix.\"\"\"\n",
    "    with engine.begin() as conn:\n",
    "        result = conn.execute(text(\"\"\"\n",
    "            SELECT sp.schedule_id, sp.sched_plot, sp.last_plot, sp.semester,\n",
    "                   s.display_name, s.max_slot\n",
    "            FROM schedule_plots sp\n",
    "            JOIN schedules s ON sp.schedule_id = s.schedule_id\n",
    "            WHERE sp.schedule_id LIKE :prefix\n",
    "            AND sp.semester = :semester\n",
    "            ORDER BY sp.schedule_id\n",
    "        \"\"\"), {\n",
    "            \"prefix\": f\"{date_prefix}%\",\n",
    "            \"semester\": semester\n",
    "        })\n",
    "        \n",
    "        plots = []\n",
    "        for row in result:\n",
    "            plots.append({\n",
    "                'schedule_id': row.schedule_id,\n",
    "                'sched_plot': row.sched_plot,\n",
    "                'has_last_plot': bool(row.last_plot),\n",
    "                'semester': row.semester,\n",
    "                'display_name': row.display_name,\n",
    "                'max_slot': row.max_slot\n",
    "            })\n",
    "        \n",
    "        return plots\n",
    "\n",
    "def cleanup_missing_plots(semester: str = SEMESTER):\n",
    "    \"\"\"Remove database entries for plots that no longer exist on disk.\"\"\"\n",
    "    try:\n",
    "        # When running as a script\n",
    "        plots_dir = os.path.join(os.path.dirname(__file__), 'static', 'plots')\n",
    "    except NameError:\n",
    "        # When running in notebook - adjust this path as needed\n",
    "        plots_dir = os.path.abspath('static/plots')  # Update this path\n",
    "    \n",
    "    with engine.begin() as conn:\n",
    "        # Get all plot records\n",
    "        result = conn.execute(text(\"\"\"\n",
    "            SELECT schedule_id, sched_plot, last_plot\n",
    "            FROM schedule_plots\n",
    "            WHERE semester = :semester\n",
    "        \"\"\"), {\"semester\": semester})\n",
    "        \n",
    "        for row in result:\n",
    "            schedule_id = row.schedule_id\n",
    "            needs_update = False\n",
    "            updates = {}\n",
    "            \n",
    "            # Check if sched_plot file exists\n",
    "            if row.sched_plot:\n",
    "                plot_path = os.path.join(plots_dir, row.sched_plot)\n",
    "                if not os.path.exists(plot_path):\n",
    "                    updates['sched_plot'] = None\n",
    "                    needs_update = True\n",
    "            \n",
    "            # Check if distribution plot file exists\n",
    "            if row.last_plot:\n",
    "                dist_plot_path = os.path.join(plots_dir, f\"{schedule_id}_dist.png\")\n",
    "                if not os.path.exists(dist_plot_path):\n",
    "                    updates['last_plot'] = 0\n",
    "                    needs_update = True\n",
    "            \n",
    "            # Update database if needed\n",
    "            if needs_update:\n",
    "                if 'sched_plot' in updates and 'last_plot' in updates:\n",
    "                    conn.execute(text(\"\"\"\n",
    "                        UPDATE schedule_plots \n",
    "                        SET sched_plot = :sched_plot, last_plot = :last_plot\n",
    "                        WHERE schedule_id = :schedule_id\n",
    "                    \"\"\"), {\n",
    "                        \"sched_plot\": updates['sched_plot'],\n",
    "                        \"last_plot\": updates['last_plot'],\n",
    "                        \"schedule_id\": schedule_id\n",
    "                    })\n",
    "                elif 'sched_plot' in updates:\n",
    "                    conn.execute(text(\"\"\"\n",
    "                        UPDATE schedule_plots \n",
    "                        SET sched_plot = :sched_plot\n",
    "                        WHERE schedule_id = :schedule_id\n",
    "                    \"\"\"), {\n",
    "                        \"sched_plot\": updates['sched_plot'],\n",
    "                        \"schedule_id\": schedule_id\n",
    "                    })\n",
    "                elif 'last_plot' in updates:\n",
    "                    conn.execute(text(\"\"\"\n",
    "                        UPDATE schedule_plots \n",
    "                        SET last_plot = :last_plot\n",
    "                        WHERE schedule_id = :schedule_id\n",
    "                    \"\"\"), {\n",
    "                        \"last_plot\": updates['last_plot'],\n",
    "                        \"schedule_id\": schedule_id\n",
    "                    })\n",
    "                \n",
    "                print(f\"Updated plot records for {schedule_id}: {updates}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de5d71c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing helper functions...\n",
      "Getting schedules for prefix: 20240620\n",
      "Found 0 schedules matching prefix '20240620'\n",
      "Found schedules: []\n",
      "All plots for prefix: 0 found\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test the helper functions.\"\"\"\n",
    "print(\"Testing helper functions...\")\n",
    "\n",
    "# Test getting schedule files\n",
    "test_prefix = \"20240620\"\n",
    "schedules = get_schedule_files(test_prefix)\n",
    "print(f\"Found schedules: {schedules}\")\n",
    "\n",
    "# Test getting plot info\n",
    "if schedules:\n",
    "  plot_info = get_schedule_plot_info(schedules[0])\n",
    "  print(f\"Plot info for {schedules[0]}: {plot_info}\")\n",
    "\n",
    "# Test getting all plots for prefix\n",
    "all_plots = get_all_plots_for_prefix(test_prefix)\n",
    "print(f\"All plots for prefix: {len(all_plots)} found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3e5f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found database at: /home/asj53/BOScheduling/myproject/data/schedules.db\n",
      "Database path: /home/asj53/BOScheduling/myproject/data/schedules.db\n",
      "Database URL: sqlite:////home/asj53/BOScheduling/myproject/data/schedules.db\n",
      "Database exists: True\n",
      "✅ Database connection successful: /home/asj53/BOScheduling/myproject/data/schedules.db\n",
      "Testing helper functions...\n",
      "✅ Database connection successful: /home/asj53/BOScheduling/myproject/data/schedules.db\n",
      "Getting schedules for prefix: 20250623\n",
      "Found 0 schedules matching prefix '20250623_'\n",
      "Found schedules: []\n",
      "All plots for prefix: 0 found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from functools import lru_cache\n",
    "from sqlalchemy import create_engine, text\n",
    "from typing import List\n",
    "\n",
    "# ── CONFIGURE ────────────────────────────────────────────────────────────────\n",
    "# Database configuration - adjust paths as needed\n",
    "def get_db_path():\n",
    "    \"\"\"Get database path, handling both script and notebook contexts.\"\"\"\n",
    "    try:\n",
    "        # When running as a script\n",
    "        script_dir = os.path.dirname(__file__)\n",
    "        return os.path.join(script_dir, '..', 'data', 'schedules.db')\n",
    "    except NameError:\n",
    "        # When running in notebook or interactive environment\n",
    "        # Try different possible locations\n",
    "        possible_paths = [\n",
    "            'schedules.db',  # Current directory\n",
    "            'data/schedules.db',  # data subdirectory\n",
    "            '../data/schedules.db',  # parent/data\n",
    "            '../../data/schedules.db',  # grandparent/data\n",
    "            '/home/asj53/BOScheduling/schedules.db',  # Absolute path guess\n",
    "            'myproject/data/schedules.db'  # Project structure\n",
    "        ]\n",
    "        \n",
    "        for path in possible_paths:\n",
    "            abs_path = os.path.abspath(path)\n",
    "            if os.path.exists(abs_path):\n",
    "                print(f\"Found database at: {abs_path}\")\n",
    "                return abs_path\n",
    "        \n",
    "        # If none found, return the first option and let user know\n",
    "        print(\"Database not found in common locations. Please update the path manually.\")\n",
    "        print(\"Tried these paths:\")\n",
    "        for path in possible_paths:\n",
    "            print(f\"  - {os.path.abspath(path)}\")\n",
    "        return os.path.abspath(possible_paths[0])\n",
    "\n",
    "def verify_db_connection():\n",
    "    \"\"\"Verify database exists and is accessible.\"\"\"\n",
    "    if not os.path.exists(DB_PATH):\n",
    "        print(f\"❌ Database file does not exist at: {DB_PATH}\")\n",
    "        print(f\"Current working directory: {os.getcwd()}\")\n",
    "        print(\"Please check the path or create the database first.\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Test connection\n",
    "        test_engine = create_engine(DB_URL, echo=False)\n",
    "        with test_engine.begin() as conn:\n",
    "            conn.execute(text(\"SELECT 1\"))\n",
    "        print(f\"✅ Database connection successful: {DB_PATH}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Database connection failed: {e}\")\n",
    "        return False\n",
    "\n",
    "DB_PATH = get_db_path()\n",
    "DB_URL = f\"sqlite:///{DB_PATH}\"\n",
    "SEMESTER = \"sp25\"  # Update as needed\n",
    "\n",
    "print(f\"Database path: {DB_PATH}\")\n",
    "print(f\"Database URL: {DB_URL}\")\n",
    "print(f\"Database exists: {os.path.exists(DB_PATH)}\")\n",
    "\n",
    "# Verify connection on import\n",
    "if not verify_db_connection():\n",
    "    print(\"\\n🔧 To fix this:\")\n",
    "    print(\"1. Update the database path in get_db_path() function\")\n",
    "    print(\"2. Or create the database at the expected location\")\n",
    "    print(\"3. Or run the database creation script first\")\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "engine = create_engine(DB_URL, echo=False)  # Set echo=True for debugging\n",
    "\n",
    "def get_schedule_files(date_prefix: str, semester: str = SEMESTER) -> List[str]:\n",
    "    \"\"\"Get schedule IDs from database that match the given date prefix.\"\"\"\n",
    "    print('Getting schedules for prefix:', date_prefix)\n",
    "    \n",
    "    with engine.begin() as conn:\n",
    "        # Fixed: Search in schedule_plots table instead of schedules table\n",
    "        # Only include schedules that also have metrics (if you want to filter by semester)\n",
    "        # OR just get all from schedule_plots if you don't need semester filtering\n",
    "        \n",
    "        if semester:\n",
    "            # Option 1: Only get schedules that have metrics with the specified semester\n",
    "            result = conn.execute(text(\"\"\"\n",
    "                SELECT DISTINCT sp.schedule_id \n",
    "                FROM schedule_plots sp\n",
    "                JOIN metrics m ON sp.schedule_id = m.schedule_id\n",
    "                WHERE sp.schedule_id LIKE :prefix \n",
    "                AND m.semester = :semester\n",
    "                ORDER BY sp.schedule_id\n",
    "            \"\"\"), {\n",
    "                \"prefix\": f\"{date_prefix}_%\",\n",
    "                \"semester\": semester\n",
    "            })\n",
    "        else:\n",
    "            # Option 2: Get all schedules from schedule_plots, regardless of metrics\n",
    "            result = conn.execute(text(\"\"\"\n",
    "                SELECT DISTINCT schedule_id \n",
    "                FROM schedule_plots\n",
    "                WHERE schedule_id LIKE :prefix \n",
    "                ORDER BY schedule_id\n",
    "            \"\"\"), {\n",
    "                \"prefix\": f\"{date_prefix}_%\"\n",
    "            })\n",
    "        \n",
    "        schedule_ids = [row.schedule_id for row in result]\n",
    "        print(f\"Found {len(schedule_ids)} schedules matching prefix '{date_prefix}_'\")\n",
    "        \n",
    "        # Debug: show some examples if found\n",
    "        if schedule_ids:\n",
    "            print(f\"Example schedule IDs found:\")\n",
    "            for i, sid in enumerate(schedule_ids[:5]):  # Show first 5\n",
    "                print(f\"  {i+1}. {sid}\")\n",
    "            if len(schedule_ids) > 5:\n",
    "                print(f\"  ... and {len(schedule_ids) - 5} more\")\n",
    "        \n",
    "        return schedule_ids\n",
    "\n",
    "\n",
    "def check_plot_exists(schedule_id: str, plot_type: str = 'sched_plot') -> bool:\n",
    "    \"\"\"Check if a plot exists in the database for the given schedule_id.\"\"\"\n",
    "    with engine.begin() as conn:\n",
    "        result = conn.execute(text(\"\"\"\n",
    "            SELECT 1 FROM schedule_plots \n",
    "            WHERE schedule_id = :schedule_id \n",
    "            AND :plot_type IS NOT NULL\n",
    "        \"\"\"), {\n",
    "            \"schedule_id\": schedule_id,\n",
    "            \"plot_type\": plot_type\n",
    "        })\n",
    "        return result.fetchone() is not None\n",
    "\n",
    "def update_plot_in_db(schedule_id: str, plot_type: str, plot_filename: str, semester: str = SEMESTER):\n",
    "    \"\"\"Update the plot information in the database.\"\"\"\n",
    "    with engine.begin() as conn:\n",
    "        # Check if record exists\n",
    "        existing = conn.execute(text(\"\"\"\n",
    "            SELECT schedule_id FROM schedule_plots \n",
    "            WHERE schedule_id = :schedule_id\n",
    "        \"\"\"), {\"schedule_id\": schedule_id}).fetchone()\n",
    "        \n",
    "        if existing:\n",
    "            # Update existing record\n",
    "            if plot_type == 'sched_plot':\n",
    "                conn.execute(text(\"\"\"\n",
    "                    UPDATE schedule_plots \n",
    "                    SET sched_plot = :plot_filename\n",
    "                    WHERE schedule_id = :schedule_id\n",
    "                \"\"\"), {\n",
    "                    \"plot_filename\": plot_filename,\n",
    "                    \"schedule_id\": schedule_id\n",
    "                })\n",
    "            elif plot_type == 'last_plot':\n",
    "                conn.execute(text(\"\"\"\n",
    "                    UPDATE schedule_plots \n",
    "                    SET last_plot = 1\n",
    "                    WHERE schedule_id = :schedule_id\n",
    "                \"\"\"), {\"schedule_id\": schedule_id})\n",
    "        else:\n",
    "            # Insert new record\n",
    "            sched_plot = plot_filename if plot_type == 'sched_plot' else None\n",
    "            last_plot = 1 if plot_type == 'last_plot' else 0\n",
    "            \n",
    "            conn.execute(text(\"\"\"\n",
    "                INSERT INTO schedule_plots (schedule_id, sched_plot, last_plot, semester)\n",
    "                VALUES (:schedule_id, :sched_plot, :last_plot, :semester)\n",
    "            \"\"\"), {\n",
    "                \"schedule_id\": schedule_id,\n",
    "                \"sched_plot\": sched_plot,\n",
    "                \"last_plot\": last_plot,\n",
    "                \"semester\": semester\n",
    "            })\n",
    "\n",
    "def plot_exists_on_disk(schedule_id: str, plot_suffix: str = '', plots_dir: str = None) -> bool:\n",
    "    \"\"\"Check if plot file exists on disk.\"\"\"\n",
    "    if plots_dir is None:\n",
    "        try:\n",
    "            # When running as a script\n",
    "            plots_dir = os.path.join(os.path.dirname(__file__), 'static', 'plots')\n",
    "        except NameError:\n",
    "            # When running in notebook - adjust this path as needed\n",
    "            plots_dir = os.path.abspath('static/plots')  # Update this path\n",
    "    \n",
    "    plot_filename = f\"{schedule_id}{plot_suffix}.png\"\n",
    "    plot_path = os.path.join(plots_dir, plot_filename)\n",
    "    return os.path.exists(plot_path)\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def generate_plots_for_files(date_prefix: str, semester: str = SEMESTER):\n",
    "    \"\"\"Generate missing schedule and distribution plots for all files matching prefix.\"\"\"\n",
    "    schedule_ids = get_schedule_files(date_prefix, semester)\n",
    "    print(\"PLOT SCHEDULE IDs:\", schedule_ids)\n",
    "    \n",
    "    for schedule_id in schedule_ids:\n",
    "        # Check and generate regular schedule plot\n",
    "        if not plot_exists_on_disk(schedule_id):\n",
    "            print(f\"Generating schedule plot for {schedule_id}\")\n",
    "            get_plot(schedule_id, schedule_id)  # Assuming get_plot function exists\n",
    "            # Update database after successful plot generation\n",
    "            plot_filename = f\"{schedule_id}.png\"\n",
    "            update_plot_in_db(schedule_id, 'sched_plot', plot_filename, semester)\n",
    "        \n",
    "        # Check and generate distribution plot\n",
    "        if not plot_exists_on_disk(schedule_id, '_dist'):\n",
    "            print(f\"Generating distribution plot for {schedule_id}\")\n",
    "            last_day(schedule_id, schedule_id)  # Assuming last_day function exists\n",
    "            # Update database after successful plot generation\n",
    "            update_plot_in_db(schedule_id, 'last_plot', f\"{schedule_id}_dist.png\", semester)\n",
    "\n",
    "def get_schedule_plot_info(schedule_id: str) -> dict:\n",
    "    \"\"\"Get plot information for a specific schedule from the database.\"\"\"\n",
    "    with engine.begin() as conn:\n",
    "        result = conn.execute(text(\"\"\"\n",
    "            SELECT schedule_id, sched_plot, last_plot, semester\n",
    "            FROM schedule_plots\n",
    "            WHERE schedule_id = :schedule_id\n",
    "        \"\"\"), {\"schedule_id\": schedule_id})\n",
    "        \n",
    "        row = result.fetchone()\n",
    "        if row:\n",
    "            return {\n",
    "                'schedule_id': row.schedule_id,\n",
    "                'sched_plot': row.sched_plot,\n",
    "                'has_last_plot': bool(row.last_plot),\n",
    "                'semester': row.semester\n",
    "            }\n",
    "        return None\n",
    "\n",
    "def get_all_plots_for_prefix(date_prefix: str, semester: str = SEMESTER) -> List[dict]:\n",
    "    \"\"\"Get all plot information for schedules matching the prefix.\"\"\"\n",
    "    with engine.begin() as conn:\n",
    "        result = conn.execute(text(\"\"\"\n",
    "            SELECT sp.schedule_id, sp.sched_plot, sp.last_plot, sp.semester,\n",
    "                   s.display_name, s.max_slot\n",
    "            FROM schedule_plots sp\n",
    "            JOIN schedules s ON sp.schedule_id = s.schedule_id\n",
    "            WHERE sp.schedule_id LIKE :prefix\n",
    "            AND sp.semester = :semester\n",
    "            ORDER BY sp.schedule_id\n",
    "        \"\"\"), {\n",
    "            \"prefix\": f\"{date_prefix}_%\",  # Changed from % to _%\n",
    "            \"semester\": semester\n",
    "        })\n",
    "        \n",
    "        plots = []\n",
    "        for row in result:\n",
    "            plots.append({\n",
    "                'schedule_id': row.schedule_id,\n",
    "                'sched_plot': row.sched_plot,\n",
    "                'has_last_plot': bool(row.last_plot),\n",
    "                'semester': row.semester,\n",
    "                'display_name': row.display_name,\n",
    "                'max_slot': row.max_slot\n",
    "            })\n",
    "        \n",
    "        return plots\n",
    "\n",
    "def cleanup_missing_plots(semester: str = SEMESTER):\n",
    "    \"\"\"Remove database entries for plots that no longer exist on disk.\"\"\"\n",
    "    try:\n",
    "        # When running as a script\n",
    "        plots_dir = os.path.join(os.path.dirname(__file__), 'static', 'plots')\n",
    "    except NameError:\n",
    "        # When running in notebook - adjust this path as needed\n",
    "        plots_dir = os.path.abspath('static/plots')  # Update this path\n",
    "    \n",
    "    with engine.begin() as conn:\n",
    "        # Get all plot records\n",
    "        result = conn.execute(text(\"\"\"\n",
    "            SELECT schedule_id, sched_plot, last_plot\n",
    "            FROM schedule_plots\n",
    "            WHERE semester = :semester\n",
    "        \"\"\"), {\"semester\": semester})\n",
    "        \n",
    "        for row in result:\n",
    "            schedule_id = row.schedule_id\n",
    "            needs_update = False\n",
    "            updates = {}\n",
    "            \n",
    "            # Check if sched_plot file exists\n",
    "            if row.sched_plot:\n",
    "                plot_path = os.path.join(plots_dir, row.sched_plot)\n",
    "                if not os.path.exists(plot_path):\n",
    "                    updates['sched_plot'] = None\n",
    "                    needs_update = True\n",
    "            \n",
    "            # Check if distribution plot file exists\n",
    "            if row.last_plot:\n",
    "                dist_plot_path = os.path.join(plots_dir, f\"{schedule_id}_dist.png\")\n",
    "                if not os.path.exists(dist_plot_path):\n",
    "                    updates['last_plot'] = 0\n",
    "                    needs_update = True\n",
    "            \n",
    "            # Update database if needed\n",
    "            if needs_update:\n",
    "                if 'sched_plot' in updates and 'last_plot' in updates:\n",
    "                    conn.execute(text(\"\"\"\n",
    "                        UPDATE schedule_plots \n",
    "                        SET sched_plot = :sched_plot, last_plot = :last_plot\n",
    "                        WHERE schedule_id = :schedule_id\n",
    "                    \"\"\"), {\n",
    "                        \"sched_plot\": updates['sched_plot'],\n",
    "                        \"last_plot\": updates['last_plot'],\n",
    "                        \"schedule_id\": schedule_id\n",
    "                    })\n",
    "                elif 'sched_plot' in updates:\n",
    "                    conn.execute(text(\"\"\"\n",
    "                        UPDATE schedule_plots \n",
    "                        SET sched_plot = :sched_plot\n",
    "                        WHERE schedule_id = :schedule_id\n",
    "                    \"\"\"), {\n",
    "                        \"sched_plot\": updates['sched_plot'],\n",
    "                        \"schedule_id\": schedule_id\n",
    "                    })\n",
    "                elif 'last_plot' in updates:\n",
    "                    conn.execute(text(\"\"\"\n",
    "                        UPDATE schedule_plots \n",
    "                        SET last_plot = :last_plot\n",
    "                        WHERE schedule_id = :schedule_id\n",
    "                    \"\"\"), {\n",
    "                        \"last_plot\": updates['last_plot'],\n",
    "                        \"schedule_id\": schedule_id\n",
    "                    })\n",
    "                \n",
    "                print(f\"Updated plot records for {schedule_id}: {updates}\")\n",
    "\n",
    "# Example usage and testing function\n",
    "def test_functions():\n",
    "    \"\"\"Test the helper functions with better error handling.\"\"\"\n",
    "    print(\"Testing helper functions...\")\n",
    "    \n",
    "    # First verify database connection\n",
    "    if not verify_db_connection():\n",
    "        print(\"Cannot proceed with tests - database connection failed\")\n",
    "        return\n",
    "    \n",
    "    # Test getting schedule files\n",
    "    test_prefix = \"20250623\"\n",
    "    try:\n",
    "        schedules = get_schedule_files(test_prefix)\n",
    "        print(f\"Found schedules: {schedules}\")\n",
    "        \n",
    "        # Test getting plot info\n",
    "        if schedules:\n",
    "            plot_info = get_schedule_plot_info(schedules[0])\n",
    "            print(f\"Plot info for {schedules[0]}: {plot_info}\")\n",
    "        \n",
    "        # Test getting all plots for prefix\n",
    "        all_plots = get_all_plots_for_prefix(test_prefix)\n",
    "        print(f\"All plots for prefix: {len(all_plots)} found\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during testing: {e}\")\n",
    "        print(\"This might be due to missing tables or data in the database\")\n",
    "\n",
    "def create_database_tables():\n",
    "    \"\"\"Create the necessary tables if they don't exist.\"\"\"\n",
    "    print(\"Creating database tables...\")\n",
    "    \n",
    "    try:\n",
    "        with engine.begin() as conn:\n",
    "            # Create schedules table\n",
    "            conn.execute(text(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS schedules (\n",
    "                  schedule_id   TEXT    PRIMARY KEY,\n",
    "                  display_name  TEXT,\n",
    "                  max_slot      INTEGER\n",
    "                );\n",
    "            \"\"\"))\n",
    "            \n",
    "            # Create metrics table  \n",
    "            conn.execute(text(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS metrics (\n",
    "                  schedule_id             TEXT    PRIMARY KEY\n",
    "                                             REFERENCES schedules(schedule_id),\n",
    "                  conflicts               INTEGER,\n",
    "                  quints                  INTEGER,\n",
    "                  quads                   INTEGER,\n",
    "                  four_in_five            INTEGER,\n",
    "                  triple_in_24h           INTEGER,\n",
    "                  triple_in_same_day      INTEGER,\n",
    "                  three_in_four           INTEGER,\n",
    "                  evening_morning_b2b     INTEGER,\n",
    "                  other_b2b               INTEGER,\n",
    "                  two_in_three            INTEGER,\n",
    "                  singular_late           INTEGER,\n",
    "                  two_large_gap           INTEGER,\n",
    "                  avg_max                 FLOAT,\n",
    "                  lateness                INTEGER,\n",
    "                  size_cutoff             INTEGER,\n",
    "                  reserved                INTEGER,\n",
    "                  num_blocks              INTEGER,\n",
    "                  alpha                   FLOAT,\n",
    "                  gamma                   FLOAT,\n",
    "                  delta                   FLOAT,\n",
    "                  vega                    FLOAT,\n",
    "                  theta                   FLOAT,\n",
    "                  large_block_size        FLOAT,\n",
    "                  large_exam_weight       FLOAT,\n",
    "                  large_block_weight      FLOAT,\n",
    "                  large_size_1            FLOAT,\n",
    "                  large_cutoff_freedom    FLOAT,\n",
    "                  tradeoff                FLOAT,\n",
    "                  flpens                  FLOAT,\n",
    "                  semester                TEXT\n",
    "                );\n",
    "            \"\"\"))\n",
    "            \n",
    "            # Create schedule_plots table (renamed from schedule_details)\n",
    "            conn.execute(text(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS schedule_plots (\n",
    "                  schedule_id   TEXT    NOT NULL\n",
    "                                           REFERENCES schedules(schedule_id),\n",
    "                  sched_plot    TEXT,\n",
    "                  last_plot     INTEGER,\n",
    "                  semester      TEXT,\n",
    "                  PRIMARY KEY (schedule_id)\n",
    "                );\n",
    "            \"\"\"))\n",
    "            \n",
    "        print(\"✅ Database tables created successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error creating tables: {e}\")\n",
    "\n",
    "# Manual path override function\n",
    "def set_database_path(path: str):\n",
    "    \"\"\"Manually set the database path if auto-detection fails.\"\"\"\n",
    "    global DB_PATH, DB_URL, engine\n",
    "    \n",
    "    DB_PATH = os.path.abspath(path)\n",
    "    DB_URL = f\"sqlite:///{DB_PATH}\"\n",
    "    engine = create_engine(DB_URL, echo=False)\n",
    "    \n",
    "    print(f\"Database path updated to: {DB_PATH}\")\n",
    "    print(f\"Database exists: {os.path.exists(DB_PATH)}\")\n",
    "    \n",
    "    return verify_db_connection()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2029dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found database at: /home/asj53/BOScheduling/myproject/data/schedules.db\n",
      "FULL DATABASE DEBUG\n",
      "================================================================================\n",
      "Sample schedule IDs from database:\n",
      "==================================================\n",
      "2025-06-28 07:25:52,018 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-28 07:25:52,019 INFO sqlalchemy.engine.Engine \n",
      "            SELECT schedule_id \n",
      "            FROM schedule_plots \n",
      "            ORDER BY schedule_id \n",
      "            LIMIT 10\n",
      "        \n",
      "2025-06-28 07:25:52,019 INFO sqlalchemy.engine.Engine [generated in 0.00076s] ()\n",
      "   1. 20250614_065847i1-30830ed058547eee431b8eed83a4feda\n",
      "   2. 20250614_065847i2-5d4672b13683d7963d5f2c95d1a5aded\n",
      "   3. 20250614_065847i3-7eee9a7019805f42ad398408c5bd6b1c\n",
      "   4. 20250614_065847i4-6286463d8ea88823a71ad71e35087207\n",
      "   5. 20250614_065847i5-5414981f3563c30b9f4ab1710ba92f7e\n",
      "   6. 20250614_071641i1-e1156f71788526c21089f219d9a4a8c8\n",
      "   7. 20250614_071641i1-e1156f71788526c21089f219d9a4a8c8_dist\n",
      "   8. 20250614_071641i2-efb1c55a835b028c53c39c78d16720ca\n",
      "   9. 20250614_071641i2-efb1c55a835b028c53c39c78d16720ca_dist\n",
      "   10. 20250614_071641i3-cd586124232f4ab68ad12df566901756\n",
      "2025-06-28 07:25:52,045 INFO sqlalchemy.engine.Engine COMMIT\n",
      "\n",
      "\n",
      "All semesters in metrics table:\n",
      "========================================\n",
      "2025-06-28 07:25:52,045 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-28 07:25:52,047 INFO sqlalchemy.engine.Engine \n",
      "            SELECT semester, COUNT(*) as count \n",
      "            FROM metrics \n",
      "            GROUP BY semester \n",
      "            ORDER BY semester\n",
      "        \n",
      "2025-06-28 07:25:52,047 INFO sqlalchemy.engine.Engine [generated in 0.00093s] ()\n",
      "   None: 14 schedules\n",
      "   sp25: 4552 schedules\n",
      "2025-06-28 07:25:52,103 INFO sqlalchemy.engine.Engine COMMIT\n",
      "\n",
      "\n",
      "Looking for schedule ID: 20250614_065847i2-5d4672b13683d7963d5f2c95d1a5aded\n",
      "Target semester: sp25\n",
      "================================================================================\n",
      "2025-06-28 07:25:52,104 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "1. Checking schedules table...\n",
      "2025-06-28 07:25:52,106 INFO sqlalchemy.engine.Engine \n",
      "            SELECT schedule_id, display_name, max_slot \n",
      "            FROM schedules \n",
      "            WHERE schedule_id = ?\n",
      "        \n",
      "2025-06-28 07:25:52,107 INFO sqlalchemy.engine.Engine [generated in 0.00079s] ('20250614_065847i2-5d4672b13683d7963d5f2c95d1a5aded',)\n",
      "❌ NOT found in schedules table\n",
      "\n",
      "2. Checking metrics table...\n",
      "2025-06-28 07:25:52,124 INFO sqlalchemy.engine.Engine \n",
      "            SELECT schedule_id, semester, conflicts, lateness \n",
      "            FROM metrics \n",
      "            WHERE schedule_id = ?\n",
      "        \n",
      "2025-06-28 07:25:52,125 INFO sqlalchemy.engine.Engine [generated in 0.00088s] ('20250614_065847i2-5d4672b13683d7963d5f2c95d1a5aded',)\n",
      "❌ NOT found in metrics table\n",
      "\n",
      "3. Testing the original JOIN query...\n",
      "2025-06-28 07:25:52,141 INFO sqlalchemy.engine.Engine \n",
      "            SELECT DISTINCT s.schedule_id, m.semester\n",
      "            FROM schedules s\n",
      "            JOIN metrics m ON s.schedule_id = m.schedule_id\n",
      "            WHERE s.schedule_id = ? \n",
      "            AND m.semester = ?\n",
      "        \n",
      "2025-06-28 07:25:52,142 INFO sqlalchemy.engine.Engine [generated in 0.00088s] ('20250614_065847i2-5d4672b13683d7963d5f2c95d1a5aded', 'sp25')\n",
      "❌ JOIN query returned no results\n",
      "\n",
      "2025-06-28 07:25:52,153 INFO sqlalchemy.engine.Engine COMMIT\n",
      "\n",
      "\n",
      "Testing prefix search for: 20250614\n",
      "Target semester: sp25\n",
      "================================================================================\n",
      "2025-06-28 07:25:52,154 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "1. All schedule IDs starting with prefix (no JOIN)...\n",
      "2025-06-28 07:25:52,156 INFO sqlalchemy.engine.Engine \n",
      "            SELECT schedule_id \n",
      "            FROM schedule_plots \n",
      "            WHERE schedule_id LIKE ?\n",
      "            ORDER BY schedule_id\n",
      "            LIMIT 10\n",
      "        \n",
      "2025-06-28 07:25:52,156 INFO sqlalchemy.engine.Engine [generated in 0.00076s] ('20250614_%',)\n",
      "Found 10 schedules starting with '20250614_':\n",
      "   20250614_065847i1-30830ed058547eee431b8eed83a4feda\n",
      "   20250614_065847i2-5d4672b13683d7963d5f2c95d1a5aded\n",
      "   20250614_065847i3-7eee9a7019805f42ad398408c5bd6b1c\n",
      "   20250614_065847i4-6286463d8ea88823a71ad71e35087207\n",
      "   20250614_065847i5-5414981f3563c30b9f4ab1710ba92f7e\n",
      "   20250614_071641i1-e1156f71788526c21089f219d9a4a8c8\n",
      "   20250614_071641i1-e1156f71788526c21089f219d9a4a8c8_dist\n",
      "   20250614_071641i2-efb1c55a835b028c53c39c78d16720ca\n",
      "   20250614_071641i2-efb1c55a835b028c53c39c78d16720ca_dist\n",
      "   20250614_071641i3-cd586124232f4ab68ad12df566901756\n",
      "\n",
      "2. Checking semesters for these schedules...\n",
      "2025-06-28 07:25:52,168 INFO sqlalchemy.engine.Engine \n",
      "                SELECT schedule_id, semester \n",
      "                FROM metrics \n",
      "                WHERE schedule_id IN (?,?,?,?,?,?,?,?,?,?)\n",
      "            \n",
      "2025-06-28 07:25:52,169 INFO sqlalchemy.engine.Engine [generated in 0.00085s] ('20250614_065847i1-30830ed058547eee431b8eed83a4feda', '20250614_065847i2-5d4672b13683d7963d5f2c95d1a5aded', '20250614_065847i3-7eee9a7019805f42ad398408c5bd6b1c', '20250614_065847i4-6286463d8ea88823a71ad71e35087207', '20250614_065847i5-5414981f3563c30b9f4ab1710ba92f7e', '20250614_071641i1-e1156f71788526c21089f219d9a4a8c8', '20250614_071641i1-e1156f71788526c21089f219d9a4a8c8_dist', '20250614_071641i2-efb1c55a835b028c53c39c78d16720ca', '20250614_071641i2-efb1c55a835b028c53c39c78d16720ca_dist', '20250614_071641i3-cd586124232f4ab68ad12df566901756')\n",
      "   ❌ 20250614_065847i1-30830ed058547eee431b8eed83a4feda -> NO METRICS FOUND\n",
      "   ❌ 20250614_065847i2-5d4672b13683d7963d5f2c95d1a5aded -> NO METRICS FOUND\n",
      "   ❌ 20250614_065847i3-7eee9a7019805f42ad398408c5bd6b1c -> NO METRICS FOUND\n",
      "   ❌ 20250614_065847i4-6286463d8ea88823a71ad71e35087207 -> NO METRICS FOUND\n",
      "   ❌ 20250614_065847i5-5414981f3563c30b9f4ab1710ba92f7e -> NO METRICS FOUND\n",
      "   ✅ 20250614_071641i1-e1156f71788526c21089f219d9a4a8c8 -> semester: sp25\n",
      "   ❌ 20250614_071641i1-e1156f71788526c21089f219d9a4a8c8_dist -> NO METRICS FOUND\n",
      "   ✅ 20250614_071641i2-efb1c55a835b028c53c39c78d16720ca -> semester: sp25\n",
      "   ❌ 20250614_071641i2-efb1c55a835b028c53c39c78d16720ca_dist -> NO METRICS FOUND\n",
      "   ✅ 20250614_071641i3-cd586124232f4ab68ad12df566901756 -> semester: sp25\n",
      "\n",
      "3. Testing full JOIN query with prefix...\n",
      "2025-06-28 07:25:52,183 INFO sqlalchemy.engine.Engine \n",
      "            SELECT DISTINCT s.schedule_id, m.semester\n",
      "            FROM schedule_plots s\n",
      "            JOIN metrics m ON s.schedule_id = m.schedule_id\n",
      "            WHERE s.schedule_id LIKE ? \n",
      "            AND m.semester = ?\n",
      "            ORDER BY s.schedule_id\n",
      "        \n",
      "2025-06-28 07:25:52,184 INFO sqlalchemy.engine.Engine [generated in 0.00091s] ('20250614_%', 'sp25')\n",
      "JOIN query returned 239 results:\n",
      "   20250614_071641i1-e1156f71788526c21089f219d9a4a8c8\n",
      "   20250614_071641i2-efb1c55a835b028c53c39c78d16720ca\n",
      "   20250614_071641i3-cd586124232f4ab68ad12df566901756\n",
      "   20250614_071641i4-97aa0dcc435280bccc6e9acfeed0af11\n",
      "   20250614_071641i5-e02ba199a0c37d1def4f1f1cdd98e22a\n",
      "   20250614_074118i1-2ce926805db1a18152c5a82aca4b7d1a\n",
      "   20250614_074118i2-95aa40a7b9f0a404c1ccdfcf3f1fff60\n",
      "   20250614_074118i3-87b065436c69790335d09c23d550df76\n",
      "   20250614_074118i4-17943a81ce37e562eb8140c8dbc92119\n",
      "   20250614_074118i5-aa8d37722cc14a1b42a50dc725316ff6\n",
      "   20250614_075849i1-b8590ffc723c011f16bf07072bfa1fb6\n",
      "   20250614_075849i10-183b109defd2967e7b20b528cf76d27f\n",
      "   20250614_075849i11-aeb5e9b76d02dd50aee1d94e59468004\n",
      "   20250614_075849i12-1da3a85fd45399342a1d7b88a80f2704\n",
      "   20250614_075849i13-c66aa6c73a8f8ac442cc2f6c3400425d\n",
      "   20250614_075849i14-bc2f69deb1aac71d6d1b132c9e260194\n",
      "   20250614_075849i15-4510658cd731da054dbc6eb5cda9581f\n",
      "   20250614_075849i16-14a6536953d30f5ef1460dda258b7e3b\n",
      "   20250614_075849i17-07c1164f7a34b88911ac8c212c07e0a4\n",
      "   20250614_075849i18-7250af83cc5000f6b43fad4d17b9ec48\n",
      "   20250614_075849i19-fe52c298959434605e7d02f6ce94ebf0\n",
      "   20250614_075849i2-e95ed4ceb62927f944e34530c5268937\n",
      "   20250614_075849i20-6dfd8e5e7682022250b3720330ad07e1\n",
      "   20250614_075849i21-24044409e5260cb31725084d9bf13530\n",
      "   20250614_075849i22-38575f29a261b426b9a9524c8c2ae2b3\n",
      "   20250614_075849i23-d6b347f98b27b330e4b6976e790998ba\n",
      "   20250614_075849i24-e57f5d4d98d9fc50ca5ccdac55e579a7\n",
      "   20250614_075849i25-78321219bd0279c1312ab6ed29bca4db\n",
      "   20250614_075849i26-878b4c69f6a55d1d46b3d04f67110e57\n",
      "   20250614_075849i27-96095a9951ca69608779c1237024d392\n",
      "   20250614_075849i28-4ebd99276c7d36e3a666eb087e541fa7\n",
      "   20250614_075849i29-aad821a31c678b3ab8284e63c8145f73\n",
      "   20250614_075849i3-8bb184c3bf3c940c508c11a83f4b592f\n",
      "   20250614_075849i30-1cf8b57cb495ea11f1e221404fa9410e\n",
      "   20250614_075849i31-d7906195d286b6c58c77960a4b8ca1a5\n",
      "   20250614_075849i32-53cb986b35a7d9441e28cddd65901951\n",
      "   20250614_075849i33-f11a906957dd565d45188aaca066c45c\n",
      "   20250614_075849i34-fe7961170e44b1aa7a71324734ddb0b1\n",
      "   20250614_075849i35-bb9ca99e65f20d23e7242bd9ff5ca218\n",
      "   20250614_075849i36-8173c74a9381334bc1acc52a40577c34\n",
      "   20250614_075849i37-b9b1e8e4d86b12116402c53de6c33c2b\n",
      "   20250614_075849i38-1c46b69b23456c06e3c3e52e71a816f6\n",
      "   20250614_075849i39-d08dbb9ebcbdecf83617e81cc86a7fe8\n",
      "   20250614_075849i4-58f47992d14ca955bbffb79604ffbd7a\n",
      "   20250614_075849i40-753c89e22723bc11a626cf6d10f7ad92\n",
      "   20250614_075849i5-211fc28ab118182296030b19b417f791\n",
      "   20250614_075849i6-d462c49271439daefca8390962689d07\n",
      "   20250614_075849i7-e46341ab8ff9da24afd15bd33c5b61b2\n",
      "   20250614_075849i8-9d43b926040da2117a403fd9a3f89282\n",
      "   20250614_075849i9-31c93b2fa35bd7b0ebe6a4de39ac0e3f\n",
      "   20250614_192306i1-88c271c6ac8f16680c7760ce37737662\n",
      "   20250614_192306i10-efc12cc4e9eee4924080103ffb8cb3ff\n",
      "   20250614_192306i100-e86418b6bbbfeef352d8c18a586ed911\n",
      "   20250614_192306i101-f9a355c91a0e5fe3d1f71ca40d38d9f8\n",
      "   20250614_192306i102-0f783b7886060f3822c0cdad0854616d\n",
      "   20250614_192306i103-a9a3d8aff8b4a6731f316c1434d654ad\n",
      "   20250614_192306i104-22819fea22eb362c232709b5c7187e4a\n",
      "   20250614_192306i105-0af5f99baafa362c37c6604afcf887c1\n",
      "   20250614_192306i106-bc0133bcd255bdbb9b0f4327c8b503fd\n",
      "   20250614_192306i107-49b175997bcee4b2332ae4b81e779210\n",
      "   20250614_192306i108-c938a04289ca5a78fe7a20af8310f8ce\n",
      "   20250614_192306i109-b0afa3913077b42ea731b8bb2a0832b0\n",
      "   20250614_192306i11-643dc5082d668033d7c4ebd4af4ba363\n",
      "   20250614_192306i110-ef01b8542d450cae83b47e0a2ccb8234\n",
      "   20250614_192306i111-e32a202837daeb512019da8f3d267f0f\n",
      "   20250614_192306i112-7d3bcd9c847bb4ea4d1144e5db8adf7b\n",
      "   20250614_192306i113-ca404054c80c4c2bbae96abf718ad802\n",
      "   20250614_192306i114-27199c46d176e9419702bb9522f617fa\n",
      "   20250614_192306i115-bcfdce8ee96e378c3123451962da98be\n",
      "   20250614_192306i116-6f275568900b37713152bc105f37c5af\n",
      "   20250614_192306i117-0abcfc3677ab4e0c5f7d69ed0aacf395\n",
      "   20250614_192306i118-1f720e92fda517c64d9fa27f446ab6c0\n",
      "   20250614_192306i119-a0820601e913ecd013f07d57c77640be\n",
      "   20250614_192306i12-8cfcc46f3e97dd5ee14ea433701f75fd\n",
      "   20250614_192306i120-223100d0736a22819c2b817b815d5845\n",
      "   20250614_192306i121-9b5199edbce0d236f0ca012c033888b9\n",
      "   20250614_192306i122-4e7f9bb88aab2d81a996fa245c22294b\n",
      "   20250614_192306i123-c1bd861e87da04ea78153f1d69bf7e7a\n",
      "   20250614_192306i124-f4a145a8d89166236243089de5ebc9dc\n",
      "   20250614_192306i125-00327be486b458c6e6512b12e4897e7b\n",
      "   20250614_192306i126-b7aeadbbdfffc3823ce568289f230c60\n",
      "   20250614_192306i127-9644d2e2e75af6ec8194f772b2d45083\n",
      "   20250614_192306i128-b2d966749f7e025f00f982bf8a51a3c6\n",
      "   20250614_192306i129-94835b0c77ca746b11accf533359fa47\n",
      "   20250614_192306i13-229d84294299373563cfad5582e6573c\n",
      "   20250614_192306i130-817006358a73a1a35d995fd509919a31\n",
      "   20250614_192306i131-749b10bf696b2f821c0091bc1e68e1fa\n",
      "   20250614_192306i132-92d9d9ba4681701e22d8dce14a7b4601\n",
      "   20250614_192306i133-078bd26ea665e57aff6caafcbbfa817f\n",
      "   20250614_192306i134-7626e0f73d8379638c29ef2c7e0aea2b\n",
      "   20250614_192306i135-7b8a23bc842587ad96b5475acb95963f\n",
      "   20250614_192306i136-dc448e95cfab126b9c1355615d4a5863\n",
      "   20250614_192306i137-3bd8123e24e22959783c46aa858cf9b0\n",
      "   20250614_192306i138-111a564af814066182e97cb7b82c1e26\n",
      "   20250614_192306i139-c97b2ce9656246158df0a4dcc6f16719\n",
      "   20250614_192306i14-ae3053e740347978092f3dba5b0f2414\n",
      "   20250614_192306i140-9013cd903892a340caa5a43c2972fac9\n",
      "   20250614_192306i141-77ea3ba4eb69aa183a1ad317005d318d\n",
      "   20250614_192306i142-3ca08dc755fe6826e69bfeecba9cfaf6\n",
      "   20250614_192306i143-8a4d218375e2e787fdd2c94f816edb40\n",
      "   20250614_192306i144-0f46a612719893bdabbd45e1e5a7c136\n",
      "   20250614_192306i145-5f135c01d691c011f68f94ae3bd40e7f\n",
      "   20250614_192306i146-9aa91940b27e721391777b9d75b7f128\n",
      "   20250614_192306i147-f92bbe50c1a7ddc36225973544d24255\n",
      "   20250614_192306i148-a2d4275bf4d00323740c4381ddf5f890\n",
      "   20250614_192306i149-17548a40f9b10699f124814d5a482e1c\n",
      "   20250614_192306i15-8eb0db5f57decf179479e5c8be013381\n",
      "   20250614_192306i150-df6c29c5f62d37ed97aab7ec3bb7333d\n",
      "   20250614_192306i151-145c71226b10591be810bd62f290c9a0\n",
      "   20250614_192306i152-23a1a38f170f5c1763f90367abfc5767\n",
      "   20250614_192306i153-aba07d40b571cd0947cdb7f0e79ed26a\n",
      "   20250614_192306i154-e4e06274bc27307167dd782810e2011a\n",
      "   20250614_192306i155-90cfe2fed13e5f0a5354f7afbab1f81d\n",
      "   20250614_192306i156-67bd7d5ee5d4387f7c968f4dd54f415a\n",
      "   20250614_192306i157-f8b60a6e93b8b2b9f70c7c798d28397f\n",
      "   20250614_192306i158-456324681a0426d819d6f15d5e3bbec2\n",
      "   20250614_192306i159-0e6b71743e093b2fd2021fb71b5a2755\n",
      "   20250614_192306i16-b414852a375a9d723e56d968b43c7da8\n",
      "   20250614_192306i160-fab900bedfa78e978dae14bb34ffcc53\n",
      "   20250614_192306i161-30a1577607ba378054af5a9db9cb07b3\n",
      "   20250614_192306i162-a7485925069e27cbfea9fd6ef185961c\n",
      "   20250614_192306i163-3f70dd47af632bc2dfd3435ef5c3f8b2\n",
      "   20250614_192306i164-5bf1347002c8e7ac577afdce6b64fac0\n",
      "   20250614_192306i165-60ef9d6996ad6eab0689d3f6a6634924\n",
      "   20250614_192306i166-7089a0c1ab69d0adfd64285cc95bd48a\n",
      "   20250614_192306i167-b04cea0748b055a2ff3f3303b6c579a6\n",
      "   20250614_192306i168-c5df3863f00ebed21232485cc6e7b9f1\n",
      "   20250614_192306i169-5b06fb3a57180d7c783d79d52a86500f\n",
      "   20250614_192306i17-110edb7cdcedd48f5bf023f031f02708\n",
      "   20250614_192306i170-19108ac3facb08bac8366e746178a0e6\n",
      "   20250614_192306i171-59643d4676349fc7cd3095f69c5664ee\n",
      "   20250614_192306i172-7335a8275a3498e03ee9929864de0d62\n",
      "   20250614_192306i173-580226d57efc46aba3962bdaa5bd5703\n",
      "   20250614_192306i174-2a535729146411992975153baaa54d46\n",
      "   20250614_192306i175-a604daff68cefb9873ce6c30e87cc480\n",
      "   20250614_192306i176-6c189e25bacce3d60d040b2ff38cb8bc\n",
      "   20250614_192306i177-c5904b582b6ce41608d000405af521a6\n",
      "   20250614_192306i178-71045229ed8769f036b9c7554e3eb28b\n",
      "   20250614_192306i179-4e4997b086a8f5a7abac0d8b9e159ce8\n",
      "   20250614_192306i18-749aa50d0e3fb840113d3bdae7165a47\n",
      "   20250614_192306i180-a2d72619e029186d246494e21c9348de\n",
      "   20250614_192306i181-ed67f247e2034a2abd5face20deff289\n",
      "   20250614_192306i182-f46888bb5ded4e10d4ff1618710f09b4\n",
      "   20250614_192306i183-098df1d9bd308e5472d31178e543d735\n",
      "   20250614_192306i184-d105ee5f588f19cdbdb6bf810c389387\n",
      "   20250614_192306i185-e81fa457ee0762603f3ee736a44a9042\n",
      "   20250614_192306i186-a8305d458c1f483fd70f8ae8d12d7108\n",
      "   20250614_192306i188-41782849568a18c8c6a4b65e72ea095f\n",
      "   20250614_192306i189-da9337b09e662ebfd15a5deb35030e5e\n",
      "   20250614_192306i19-14d2e5cb0c12447989f58819cc3fd3d3\n",
      "   20250614_192306i190-2b62f0c27278d38b0155846365c8a0a9\n",
      "   20250614_192306i2-a97419ede372d644c04aefa813a71c74\n",
      "   20250614_192306i20-8dd548d6fc7c6482274eeb4b4821b9b8\n",
      "   20250614_192306i21-dc800016dd0a34c5e55feabba7fa9133\n",
      "   20250614_192306i22-b7d3e8aaaed636ffb5ec59c34c98ac7b\n",
      "   20250614_192306i23-dadb513c68410627968d932edeecb95a\n",
      "   20250614_192306i24-6c0ed36d9503ed9193b727059a1fca4d\n",
      "   20250614_192306i25-70789b1153229aea0b165361fe105e77\n",
      "   20250614_192306i26-e7e302df1c786c5ac7a2a82fca775a3a\n",
      "   20250614_192306i27-ccedb2aea227ee7c839d429ffb307090\n",
      "   20250614_192306i28-f77ab74e1350742aa2bf461c7028ffbe\n",
      "   20250614_192306i29-b841f75cc2ece8aa01303e36f22146b7\n",
      "   20250614_192306i3-b4f27335b3248e6017fb6eb48d7871f8\n",
      "   20250614_192306i30-812b144b141744107638e089258e4d93\n",
      "   20250614_192306i31-1342ca27cc5159c4ab46907848b60f5f\n",
      "   20250614_192306i32-699ba935ce96b374aa71f33694d16136\n",
      "   20250614_192306i33-179366c32a03c5e0be748b969662a899\n",
      "   20250614_192306i34-659c3e528400cca081d28a50c2595262\n",
      "   20250614_192306i35-8ae1f1c2b8dcc1b86846d1d1a5c21371\n",
      "   20250614_192306i36-e7dee4b0cc8e8afefe0e4ed4a6313ca0\n",
      "   20250614_192306i37-c261c9a2bd9ce1a913993701a59ba2f4\n",
      "   20250614_192306i38-3e84957e52fba0be95c87200f8f590dc\n",
      "   20250614_192306i39-c4c98088c07559e10f1331da0c229079\n",
      "   20250614_192306i4-d8725c9c5482fccf1e186c93284d17b6\n",
      "   20250614_192306i40-849f406a55945ca366ccf7a19af7f301\n",
      "   20250614_192306i41-d35efdd8060dfb88a9e4f1150394df55\n",
      "   20250614_192306i42-f6564b471241b94acb3d4a2aad77eb43\n",
      "   20250614_192306i43-fe6f51cb89f5b6fa929cf3ab2fc465de\n",
      "   20250614_192306i44-121c7cfecce35b7c9979f1c50ed669e6\n",
      "   20250614_192306i45-c26157a0370bf55f16c21cb3aa1bce50\n",
      "   20250614_192306i46-4c1c1dd66b9ffacb1c5605205eac415f\n",
      "   20250614_192306i47-75387112fef49795e951c4202979052b\n",
      "   20250614_192306i48-866539488a7983338aa44d0e7d6860c6\n",
      "   20250614_192306i49-4a7a3bf549c0dda5da161e14ee1b33fa\n",
      "   20250614_192306i5-9738bd25fa2cedc980a512f9f36ee27b\n",
      "   20250614_192306i50-01510e3817398aef28a46fa260b0696a\n",
      "   20250614_192306i51-455ccca9505a20cf8044204b7a169f96\n",
      "   20250614_192306i52-1530dc9668e003b01f70b946fdf041fe\n",
      "   20250614_192306i53-44ec4ed699776ec5c581e36885cc4f5e\n",
      "   20250614_192306i54-b960cfdf9a4c00c231be66609de6545b\n",
      "   20250614_192306i55-64eefbb279df0577700cbfa3a7a2fb89\n",
      "   20250614_192306i56-1d19b3762902f9cc3730a2d1eabffe3b\n",
      "   20250614_192306i57-b5e4f9b351581bd6c2b4dc610ff79907\n",
      "   20250614_192306i58-6989a8de2bb881b17fbc4ec3d14a61a4\n",
      "   20250614_192306i59-5d5cda608f3c7d976b26d60df42b4989\n",
      "   20250614_192306i6-543aa96d2801f8bad578af1a592d1e52\n",
      "   20250614_192306i60-c086bde7c5b4e6a74b0b312e80affd41\n",
      "   20250614_192306i61-cfc6bb008f4e4db799da498531f2295b\n",
      "   20250614_192306i62-05476a94fded0a4e1560ade157643546\n",
      "   20250614_192306i63-dd50bc491cdb93c600279d4540a95410\n",
      "   20250614_192306i64-ac29d2644da4ee812c020dd5713549de\n",
      "   20250614_192306i65-d5bdff11ed806fe6785614d8f4505b69\n",
      "   20250614_192306i66-2e2d714071a28cc4c6aed197a1e683ad\n",
      "   20250614_192306i67-854e6ee3a829681fc5eb1db51c640d14\n",
      "   20250614_192306i68-e243035c3158a906a77896ba71ce78fc\n",
      "   20250614_192306i69-a1e479c271b33bc2e62f458700baa7bc\n",
      "   20250614_192306i7-7bfc522e853539eb4cbe7696ab10be51\n",
      "   20250614_192306i70-16f6e9202bd48632144f0e19cb488162\n",
      "   20250614_192306i71-36413d79ba463bd85a0f50bb90023654\n",
      "   20250614_192306i72-b7e246e8befc47a481b1ad5059c30836\n",
      "   20250614_192306i73-2e24d719152fb232781e6600cf7894fb\n",
      "   20250614_192306i74-7ab4339fe01be34123334b3c4462a603\n",
      "   20250614_192306i75-1e01350f9105362cdf4eb38cbc3bf2e5\n",
      "   20250614_192306i76-eca4e070785088464361f6f06fe7807e\n",
      "   20250614_192306i77-8c0f2373e9d01156e1f59e24ae6483d8\n",
      "   20250614_192306i78-2daada8cf9f92d5dd5b8b5c427a51a53\n",
      "   20250614_192306i79-d4170d24c1ea4cf6b4d7aa75d7bde4f8\n",
      "   20250614_192306i8-303945b9229833556b70a881055cdea7\n",
      "   20250614_192306i80-ef673b4d340cabbb753ce67c25c24905\n",
      "   20250614_192306i81-d70ae3a0c95f83b7889fc75d2e316577\n",
      "   20250614_192306i82-006d6106a164801d6c072e9f458a6028\n",
      "   20250614_192306i83-97f2593c409dd0f8dc20b8d4ddecf378\n",
      "   20250614_192306i84-d6eaa0d726406daece035ba3ddded8a1\n",
      "   20250614_192306i85-ae7bd6aa6cdcf62488bd4a04cd18bcef\n",
      "   20250614_192306i86-9d6405573bd06ca54b1449ec26fd9bae\n",
      "   20250614_192306i87-898f94291d22c10ee1b763b5404085b2\n",
      "   20250614_192306i88-961be3183a44e926c324162558ff9418\n",
      "   20250614_192306i89-938ec509c131b1acc8cf709266e3d523\n",
      "   20250614_192306i9-fc285d76cc39ba548e4ff3963e753b88\n",
      "   20250614_192306i90-d6897b399519944ed8ee4a724ff536ad\n",
      "   20250614_192306i91-32f64d4a7b208aa752c29c96042ba25a\n",
      "   20250614_192306i92-e4b7683bdca8a06bf190e52e879dc05a\n",
      "   20250614_192306i93-e03b880e5a9410ed6da6eab9d45bd732\n",
      "   20250614_192306i94-387eb5c7749bc6520a0ae82f6bcec62b\n",
      "   20250614_192306i95-f87a6aa5781164ae48ea621dcfa2205a\n",
      "   20250614_192306i96-f06ad7fa3d0e7398bbd896649ecb6738\n",
      "   20250614_192306i97-d060a30596adf990e7d62d7a79ed0766\n",
      "   20250614_192306i98-289bb3dea7554bf43613514ca6337ae4\n",
      "   20250614_192306i99-52b5b4fad2a7ae28425bc942d6e3ad86\n",
      "2025-06-28 07:25:52,429 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Use the same database path from your existing code\n",
    "DB_PATH = get_db_path()\n",
    "DB_URL = f\"sqlite:///{DB_PATH}\"\n",
    "engine = create_engine(DB_URL, echo=True)  # Enable echo to see SQL queries\n",
    "\n",
    "def debug_specific_schedule_id():\n",
    "    \"\"\"Debug the specific schedule ID you mentioned.\"\"\"\n",
    "    target_schedule_id = \"20250614_065847i2-5d4672b13683d7963d5f2c95d1a5aded\"\n",
    "    target_semester = \"sp25\"\n",
    "    \n",
    "    print(f\"Looking for schedule ID: {target_schedule_id}\")\n",
    "    print(f\"Target semester: {target_semester}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    with engine.begin() as conn:\n",
    "        # 1. Check if the schedule exists in schedules table\n",
    "        print(\"1. Checking schedules table...\")\n",
    "        result = conn.execute(text(\"\"\"\n",
    "            SELECT schedule_id, display_name, max_slot \n",
    "            FROM schedules \n",
    "            WHERE schedule_id = :schedule_id\n",
    "        \"\"\"), {\"schedule_id\": target_schedule_id})\n",
    "        \n",
    "        schedule_row = result.fetchone()\n",
    "        if schedule_row:\n",
    "            print(f\"✅ Found in schedules table:\")\n",
    "            print(f\"   ID: {schedule_row.schedule_id}\")\n",
    "            print(f\"   Display Name: {schedule_row.display_name}\")\n",
    "            print(f\"   Max Slot: {schedule_row.max_slot}\")\n",
    "        else:\n",
    "            print(\"❌ NOT found in schedules table\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        # 2. Check if it exists in metrics table\n",
    "        print(\"2. Checking metrics table...\")\n",
    "        result = conn.execute(text(\"\"\"\n",
    "            SELECT schedule_id, semester, conflicts, lateness \n",
    "            FROM metrics \n",
    "            WHERE schedule_id = :schedule_id\n",
    "        \"\"\"), {\"schedule_id\": target_schedule_id})\n",
    "        \n",
    "        metrics_row = result.fetchone()\n",
    "        if metrics_row:\n",
    "            print(f\"✅ Found in metrics table:\")\n",
    "            print(f\"   ID: {metrics_row.schedule_id}\")\n",
    "            print(f\"   Semester: {metrics_row.semester}\")\n",
    "            print(f\"   Conflicts: {metrics_row.conflicts}\")\n",
    "            print(f\"   Lateness: {metrics_row.lateness}\")\n",
    "        else:\n",
    "            print(\"❌ NOT found in metrics table\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        # 3. Check if semester matches\n",
    "        if metrics_row and metrics_row.semester != target_semester:\n",
    "            print(f\"⚠️  Semester mismatch! Expected '{target_semester}', found '{metrics_row.semester}'\")\n",
    "        \n",
    "        # 4. Try the JOIN query that was failing\n",
    "        print(\"3. Testing the original JOIN query...\")\n",
    "        result = conn.execute(text(\"\"\"\n",
    "            SELECT DISTINCT s.schedule_id, m.semester\n",
    "            FROM schedules s\n",
    "            JOIN metrics m ON s.schedule_id = m.schedule_id\n",
    "            WHERE s.schedule_id = :schedule_id \n",
    "            AND m.semester = :semester\n",
    "        \"\"\"), {\n",
    "            \"schedule_id\": target_schedule_id,\n",
    "            \"semester\": target_semester\n",
    "        })\n",
    "        \n",
    "        join_row = result.fetchone()\n",
    "        if join_row:\n",
    "            print(f\"✅ JOIN query successful:\")\n",
    "            print(f\"   ID: {join_row.schedule_id}\")\n",
    "            print(f\"   Semester: {join_row.semester}\")\n",
    "        else:\n",
    "            print(\"❌ JOIN query returned no results\")\n",
    "        \n",
    "        print()\n",
    "\n",
    "def debug_prefix_search():\n",
    "    \"\"\"Debug the prefix search that's been failing.\"\"\"\n",
    "    date_prefix = \"20250614\"\n",
    "    target_semester = \"sp25\"\n",
    "    \n",
    "    print(f\"Testing prefix search for: {date_prefix}\")\n",
    "    print(f\"Target semester: {target_semester}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    with engine.begin() as conn:\n",
    "        # 1. Check schedules that start with the date prefix\n",
    "        print(\"1. All schedule IDs starting with prefix (no JOIN)...\")\n",
    "        result = conn.execute(text(\"\"\"\n",
    "            SELECT schedule_id \n",
    "            FROM schedule_plots \n",
    "            WHERE schedule_id LIKE :prefix\n",
    "            ORDER BY schedule_id\n",
    "            LIMIT 10\n",
    "        \"\"\"), {\"prefix\": f\"{date_prefix}_%\"})\n",
    "        \n",
    "        schedules_only = [row.schedule_id for row in result]\n",
    "        print(f\"Found {len(schedules_only)} schedules starting with '{date_prefix}_':\")\n",
    "        for sid in schedules_only:\n",
    "            print(f\"   {sid}\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        # 2. Check what semesters exist for these schedules\n",
    "        if schedules_only:\n",
    "            print(\"2. Checking semesters for these schedules...\")\n",
    "            placeholders = ','.join([':param' + str(i) for i in range(len(schedules_only))])\n",
    "            params = {f'param{i}': sid for i, sid in enumerate(schedules_only)}\n",
    "            \n",
    "            result = conn.execute(text(f\"\"\"\n",
    "                SELECT schedule_id, semester \n",
    "                FROM metrics \n",
    "                WHERE schedule_id IN ({placeholders})\n",
    "            \"\"\"), params)\n",
    "            \n",
    "            semester_info = {row.schedule_id: row.semester for row in result}\n",
    "            \n",
    "            for sid in schedules_only:\n",
    "                if sid in semester_info:\n",
    "                    semester = semester_info[sid]\n",
    "                    match_indicator = \"✅\" if semester == target_semester else \"❌\"\n",
    "                    print(f\"   {match_indicator} {sid} -> semester: {semester}\")\n",
    "                else:\n",
    "                    print(f\"   ❌ {sid} -> NO METRICS FOUND\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        # 3. Try the full JOIN with prefix\n",
    "        print(\"3. Testing full JOIN query with prefix...\")\n",
    "        result = conn.execute(text(\"\"\"\n",
    "            SELECT DISTINCT s.schedule_id, m.semester\n",
    "            FROM schedule_plots s\n",
    "            JOIN metrics m ON s.schedule_id = m.schedule_id\n",
    "            WHERE s.schedule_id LIKE :prefix \n",
    "            AND m.semester = :semester\n",
    "            ORDER BY s.schedule_id\n",
    "        \"\"\"), {\n",
    "            \"prefix\": f\"{date_prefix}_%\",\n",
    "            \"semester\": target_semester\n",
    "        })\n",
    "        \n",
    "        join_results = [row.schedule_id for row in result]\n",
    "        print(f\"JOIN query returned {len(join_results)} results:\")\n",
    "        for sid in join_results:\n",
    "            print(f\"   {sid}\")\n",
    "\n",
    "def show_all_semesters():\n",
    "    \"\"\"Show all unique semesters in the database.\"\"\"\n",
    "    print(\"All semesters in metrics table:\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    with engine.begin() as conn:\n",
    "        result = conn.execute(text(\"\"\"\n",
    "            SELECT semester, COUNT(*) as count \n",
    "            FROM metrics \n",
    "            GROUP BY semester \n",
    "            ORDER BY semester\n",
    "        \"\"\"))\n",
    "        \n",
    "        for row in result:\n",
    "            print(f\"   {row.semester}: {row.count} schedules\")\n",
    "\n",
    "def show_sample_schedule_ids():\n",
    "    \"\"\"Show sample schedule IDs to understand the format.\"\"\"\n",
    "    print(\"Sample schedule IDs from database:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    with engine.begin() as conn:\n",
    "        result = conn.execute(text(\"\"\"\n",
    "            SELECT schedule_id \n",
    "            FROM schedule_plots \n",
    "            ORDER BY schedule_id \n",
    "            LIMIT 10\n",
    "        \"\"\"))\n",
    "        \n",
    "        for i, row in enumerate(result, 1):\n",
    "            print(f\"   {i}. {row.schedule_id}\")\n",
    "\n",
    "# Main debug function\n",
    "def full_debug():\n",
    "    \"\"\"Run all debug functions.\"\"\"\n",
    "    print(\"FULL DATABASE DEBUG\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        show_sample_schedule_ids()\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        show_all_semesters()\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        debug_specific_schedule_id()\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        debug_prefix_search()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during debug: {e}\")\n",
    "        print(\"Make sure to update DB_PATH at the top of this script!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    full_debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a105c24c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bo-opt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
